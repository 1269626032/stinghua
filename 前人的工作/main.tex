\documentclass{amsart}

\usepackage{ctex}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{cite}
\usepackage{wyz}


\title{传感器故障诊断和减小}
\author{}
\date{}

\begin{document}

\maketitle
\tableofcontents

\section{前人的工作}

\subsection{故障诊断}
\subsection{故障减小}
\subsection{曝光异常}
文献 \cite{liliming} 本文研究了几种典型机器学习算法在不同图像降质因素作用下的人脸识别性能,进一步分析了上述算法的鲁棒性。
从仿真结果来看,
对于椒盐噪声及运动模糊影响的人脸图像,
PCA算法鲁棒性较好,
但该算法性能显著依赖于图像曝光条件影响。
相比之下,当图像曝光条件不佳时,采用RBFNN作为人脸识别算法具有相对较好的鲁棒性。
文献说说明了图像降质数学模型
\begin{enumerate}
\item 椒盐噪声
  实验研究表明,摄像机拍摄图像过程中,图像传感器、传输信道、解码处理等部件或因素将引入椒盐噪声,
  在图像上呈现黑白杂点,进而影响后续图像处理。
  设图像$I(x,y)$为N位图,椒盐噪声密度为$d_{xp}$.
  满足$d_{xp}\in [0,1]$.
  ,则则叠加椒盐噪声后的图像可以表示为:
  \begin{equation}
    \label{eq:01}
  \left\{\begin{array}{l}
g(x, y)=I(x, y) * \gamma(x, y) \\
\operatorname{Prob}(\gamma(x, y)=0)=\frac{d_{s p}}{2} \\
\operatorname{Prob}\left(\gamma(x, y)=\frac{2^{N}-1}{I(x, y)}\right)=\frac{d_{\operatorname{sen}}}{2} \\
\operatorname{Prob}(\gamma(x, y)=1)=1-d_{s p}
\end{array}\right.
  \end{equation}

\item 曝光异常
  同态滤波方法利用光照反射模型,
  把频率过滤和灰度变换结合,
  可以在不损失图像细节的前提下调解图像的光照条件。
  考虑到同态滤波具有上述特点,
  因此本文将其用作曝光异常的图像仿真方法。
  设原始图像为,$I(x,y)$,首先对其取对数并做傅里叶变换,提取高频及低频分量:
  \begin{equation}
    \label{eq:02}
Z(u, v)=F(z(x, y))=F(\ln (I(x, y))).
  \end{equation}

  之后,采用频域滤波函数对图像进行增强处理,
  本文采用高斯型高通滤波器作为滤波函数,处理如式\ref{eq:03}所示。
  其中M,N分别表示图像的行、列像素数。
  $D_0$为截止频率,$c$为锐化系数,$R_h$为高频增益,$R_t$为低频增益。

  \begin{equation}
    \label{eq:03}
\left\{\begin{array}{l}
S(u, v)=H(u, v) \cdot Z(u, v) \\
H(u, v)=\left(R_{h}-R_{l}\right) \cdot \gamma(u, v)+R_{l} \\
\gamma(u, v)=\left(1-\exp \left(-c \cdot\left(\frac{D(u, v)}{D_{0}}\right)^{2}\right)\right) \\
D(u, v)=\left(\left(u-\frac{M}{2}\right)^{2}+\left(v-\frac{N}{2}\right)^{2}\right)^{0.5}
\end{array}\right.
  \end{equation}

  最后,对频域图像做傅里叶反变换并取指数,计
  算过程如式\ref{eq:04}所示。

  \begin{equation}
    \label{eq:04}
g(x, y)=e^{s(x, y)}=e^{F-1}(S(u, v))
  \end{equation}

\item 运动模糊

  在照片曝光期间,相机与被摄物体之间发生相对运动造成的图像模糊称为运动模糊。
  受运动模糊影响的图像往往在视觉上表现为图像像素整体沿某一方向具有拖影效果。
  当像素位移量偏大时,将严重影响图像质量,从而降低人脸识别准确率。
  考虑到变速或非直线运动在一定条件下可以被分解为分段匀速直线运动,因此匀速直线运动造成的运动模糊具有普适的研究意义。
  从物理场景上看,图像发生运动模糊的原因是被摄图像经过一定距离延迟后再进行叠加。将静止条件下的图像表示为$I(x,y)$.
  设快门打开期间,图像传感器与被摄物体保持水平
  匀速直线运动,则图像褪化模型可以表示为示:
  \begin{equation}
    \label{eq:05}
g(x, y)=\frac{1}{L} \sum_{i=0}^{L} f(x-i, y) \Delta t
  \end{equation}
  其中,$L$表示图像发生整体位移的像素长度近似值。
\end{enumerate}


\cite{gaohuihuang}
准确判断巡检图片中无效图片因为巡检图片随着列车的行驶不间断地拍摄,因而在列车进站、临时停车等因素造成告诉摄像机摄入大量重复图片,为接触网异常检测增加了较多额外工作量。
除此之外,因为列车走向可能正对太阳造成曝光过度,或者因为夜间行驶造成巡检图片光线不足进而缺少必要的细节信息
。本系统需要有效检测出以上无效图片,标记图片信息并提示系统用户。
随机概率统计过滤无效图片

图像曝光过度或者光线过暗会造成图像丢失细节信息。
为了确保无效图片对绝缘子的识别与异常检测造成干扰,需要在巡检图片中判定
无效图片并做标记便于系统查询。
  \begin{equation}
    \label{eq:06}
\begin{array}{l}
\text { FlagBright }(\mathrm{x}, \mathrm{y})=\left\{\begin{array}{ll}
1, & I(x, y)>215 \\
0, & I(x, y) \leq 215
\end{array}\right. \\
\text { FlagDark }(\mathrm{x}, \mathrm{y})=\left\{\begin{array}{ll}
1, & I(x, y)<30 \\
0, & I(x, y) \geq 30
\end{array}\right.
\end{array}
\end{equation}
图像无效的判别公式如 \ref{eq:07}所示。
\begin{equation}
  \label{eq:07}
\operatorname{ImgErr}=\left\{\begin{array}{cc}
1, & \text { if } \frac{\left(\sum_{i=1}^{\text {width }} \sum_{j=1}^{\text {height }} \operatorname{Flag} \operatorname{Bright}(x, y)\right)}{\text { width * height }}>80 \% \\
\text { 1, } \quad \text { if } \frac{\left(\sum_{i=1}^{\text {width }} \sum_{j=1}^{\text {height }} \operatorname{Flag} \operatorname{Dark}(x, y)\right)}{\text { width * height }}>80 \% & \text { else } \\
0, & \text { when }
\end{array}\right.
\end{equation}

剔除部分重复拍摄照片
(1)通过观察大量巡检图片,取倾斜角在[84~96]之间的直线称为偏竖直直线。
(2)对 ROI 区域内图像进行 Hough 变换提取直线信息,并保留偏竖直直线数
据.
(3)比较直线分布区间内有最多竖直直线数,取区间数值小(即巡检图片中左侧位置)的线段的中心点横坐标标定接触网支撑结构位置 w,当该位置处于原图 ROI 位置宽度 width/6 处左侧时,认定该位置为不重叠区域,其他区域为重叠区域。
图像增强
(1)对比度增强
(2)中值滤波(文章没有提到这种方法)

\subsection{图像处理}
\label{sec:02}

\subsubsection{图像增强}
\label{sec:0201}

文献\cite{许欣}(1)提出了一种快速Retinex图像增强方法,模拟了人类视觉系统的全局和局部自适
应性.
(2)提出了一种改进的自动颜色均衡化方法,用于图像对比度的增强.
(3)提出了一种改进的结合视觉感知特性的变分框架下的彩色图像增强方法.
(4)提出了一种结合视觉特性的梯度域图像增强方法.
(5)针对同一图像采用不同增强方法处理的结果之间可存在互补优缺点的特点,提出了采用梯度域融合的方法改善图像视觉效果的增强方法.


基于核的Retinex及其反对称化
Bena]lmfo等睇1提出了Retinex基于核函数的实现(Kernel Based Retinex.,KBR),其形式为
\begin{equation}
  \label{eq:08}
\begin{aligned}
L(x)=& \sum_{v \in \Omega} w(x, y) f\left(\frac{I(x)}{I(y)}\right) \operatorname{sign}^{+}(I(y)-I(x)) \\
&+\sum_{v \in \Omega} w(x, y) \operatorname{sign}^{-}(I(y)-I(x))
\end{aligned}
\end{equation}

其中,f(·)为对像素值间的比值进行调整的函数,
\begin{equation}
  \label{eq:09}
\operatorname{sign}^{+}(\xi)=\left\{\begin{array}{ll}
1, & \text { if } \xi>0 \\
\frac{1}{2}, & \text { if } \xi=0, \quad \operatorname{sign}^{-}(\xi)=1-\operatorname{sign}^{+}(\xi) \\
0, & \text { if } \xi<0
\end{array}\right.
\end{equation}

核$w(x,y)$为$||x-y||$的函数,具有对称性,且$\sum_{y\in \Omega}(x,y)=1,\forall x \in \Omega$.
此形式的性质满足原有Retinex方法的特点,即可消除彩色图像色偏,可增强欠曝光图像中的细节,只提高像素亮度值等.
在此基础上,他们还对KBR作了“反对称化”,形式


其中,$sign_{0}(·)$为符号函数,此形式改变了原有的各种Retinex:实现方法(若不考虑色调重整的步骤)只能提高图像亮度的特点,既可处理欠曝光图像,也可处理过曝光图像.他们还指出了反对称化的KBR与ACE模型的关系.



\begin{enumerate}
\item 1.2.1频域和空域图像增强方法
按照进行处理所在空间的不同,常见的图像增强方法可分为频域处理方法和空域处
理方法两类
\begin{enumerate}
\item频域增强方法
  频域方法一般需借助\textbf{傅里叶分析}等变换方法将圈像转换至频率域后再做\textbf{滤波}等处理.
\textbf{同态滤波器}(Homomomorphic Filtering)由Oppenheim等提出,原用于声波的分析和合成,其步骤是将信号转至频域后进行非线性滤波,最后再转回时域.
  后有学者将其用于其他信号及图像的增强.
  方法通过将图像分解为照度和反射两部分分量,同时进行灰度范围的压缩和对比度增强来改进一幅图像的外观.
  通过对数运算,被视作乘性噪声的照度成分可被转化为加性噪声.
  图像中的照度和反射成分本是不可明确分开的,但二者在频域中的位置可大致确定.
  图像中的高频成分往往对应反射分量,而低频分量则对应照度在空间的变化.
  通过压制低频分量,扩大高频分量,即可有效改善图像的视觉效果.
  Polesel等提出了一种非锐化掩模(Unsharp Masking)用于图像对比度增强,方法采用
  \textbf{自适应滤波器}控制锐化路径,对图像中细节区域进行较大的增强,而对平坦区域不增强或进行较小增强.G
  uillon等同样基于自适应滤波器掩模,将非线性低通和高通滤波器结合,对图像进行同时的噪声消除和增强处理.
  陈强等通过调制传递函数(Modulation Transfer Function,MTF)补偿调整图像的光能分配,达到增强图像中细节和边缘的目的,进行遥感图像的复原和增强.
\item空域增强方法
在图像处理中,空域是指由像素点组成的空间,而空域方法则直接作用于图像中的
像素点,可表示为以下的算子形式
g
\begin{equation}
  \label{eq:10}
  g(x,y)=E_H(f(x,y))
\end{equation}
其中,$y(x,y)$和$g(x,y)$分别为增强前后的图像,而$E_H$代表增强操作算子.
如果$E_h$仅定义在每个$(x,y)$像素点上,则玩为一种点操作;
如果玩定义在$(x,y)$的某个邻域上,则玩常称为模板操作.
也有的增强方法在图像梯度场$Vf(x,Y)$上进行操作,也可将其归为空域方法.
空域方法按处理策略的不同,又可分为全局处理的方法和区域自适应处理的方法.
全局处理的方法较为简单,不考虑图像中像素点的空间分布,仅对图像中的像素值进行全局一致的调整;
较复杂的区域自适应方法则基于诸如局部对比度、边缘强度等区域信息,或采用基于偏微分方程或变分模型的描述形式.


较多的图像增强算子玩作用于单幅图像$f(x,y)$,也有的增强算子岛作用于一系列图像
$f_1(x,y),f_2(x,y),\dots,f_n(x,y)$.
简单的作用于多幅图像的增强操作可对数幅图像进行对应点位的算术和逻辑运算,以得到一幅新图像.
我们也可根据应用的具体目的设计更复杂的图像间增强操作方法.

本论文主要讨论空域的图像增强方法.
\end{enumerate}
\item 色调映射
  色调映射是在有限动态范围媒介上近似显示高动态范甩图像的一项计算机图形学技术,也是一种增强处理.
我们平常可见的场景中的最大亮度(如晴天的太阳)和最小亮度(如夜空中的星星)的
强度之间的比值可高达$10^9$至$10^{10}$,按照动态范围和输出媒介的动态范围之间的大小关系,场景可分为低动态范甬(LowDynamic Range,LDR)、标准动态范N(StanoardDynamicRange,SDR)和高动态范围(HighDynamicRange,VIII)R)三类.
从SDR场景获得的图像不需进行处理即可由输出媒介直接显示,而从LDR和HDR场景获得的图像分别需进行动态范围托伸和压缩处理.
从本质上来讲.色调映射要解决的问题是进行大幅度的对比度衰减.
将场景亮度变换到可以显示的范围,同时要保持图像细节与颜色等对于表现原始场景所必须的重要的信息

简单的全局色调映射方法采用对数函数、伽玛校正等处理图像像素值,从而对图像动态范围进行全局调整.
Braun等的方法中使用了稍复杂的S形曲线.
即Sigmoidal函数进行灰度值调整,且在函数参数设置时考虑了图像的灰度均值和方差以上介绍的全局方法实现简单、运行速度快,但对于远超过监视器显示范嗣的高动态范同图像往往易导致图像部分区域细节丢失,不能得到好的效果通常,电子设备(如CCD等)以线性方式记录进入镜头的光照强度,这与人眼感知到的场景是不一样的较好的色调映射方法必须考虑人类视觉系统的特性,以使增强结果图像接近人眼直接观察到的场景故更合适的方法是采用区域自适应的方法,如基于Retlnex理论的方法,基于梯度域操作的方法等
\item 对比度增强
  图像对比度有多种定义,一般是指图像中各部分之间灰度级反差的程度.
  对比度增强是一种增强原图中各部分间反差的方法.


  直方图调整是指按照一定的映射对图像的像素值进行调整以增强图像对比度的方法.
  灰度直方图口71是灰度级的函数,描述的是图像中具有该灰度级的像素的个数:其横坐
  标是灰度级,纵坐标是该灰度出现的频率或像素的个数.


  直方图调整映射的形式可以是事先确定的,如采用对数函数、Sigmoidal数的形式等,也可以考虑图像的具体情况进行确定.
  其中,直方图均衡化使像素灰度值分布满足(或近似满足)均匀分布.
  设图像的(离散)直方图为$h(n)$,其可视为未归一化的图像像素值分布概率密度函数.
  将其归一化,并记为$p(n)$,则$c[n]=\sum_{i=0}^n$为累计分布函数(Cumulative Distribution Function,CDF).
  将CDF拉伸至像素值动态范围,则可得到直方图均衡化的映射函数,即
  \begin{equation}
    \label{eq:11}
    T[n]=\left\lfloor 255 \sum_{j=0}^{n} p(j)+0.5\right\rfloor
  \end{equation}
  其中,$\lfloor.\rfloor$ 表示不大于自变量的最大整数.
  这里假设处理的是8位图像,即像素值的取值范
  围为区间$『0,255\rfloor$中的整数.
  以上描述的是离散形式的直方图均衡化,接下来介绍连续形式的表达.
  设像素值为归一化到[o,1】之间的实数,己归一化的直方图(即像素值概率分布密度)为日(s),则直方图均衡化的映射为
  \begin{equation}
    \label{eq:12}
   T(s)=\int_{0}^s H(s) d s
  \end{equation}


  另一种直方图调整方法称为直方图规定化,它可使处理后的直方图分布满足用户给定或期望的任意形式,而不限于均匀分布.
  针对直方图均衡化易对图像产生“过增强”的现象。
  Arici等睁引在直方图均衡化方法的基础上增加了一些约束,实现了根据图像自身特性的自适应直方图规定化.
  他们定义了如下关于调整后直方图h的目标函数,
  \begin{equation}
    \label{eq:13}
    f(\boldsymbol{h})=\left\|\boldsymbol{h}-\boldsymbol{h}_{i}\right\|_{2}^{2}+\lambda\|\boldsymbol{h}-\boldsymbol{u}\|_{2}^{2}+\gamma\|\boldsymbol{D} \boldsymbol{h}\|_{2}^{2}
  \end{equation}
  其中。$h$为目标图像的直方图,$u$为均匀分布的直方图,$h_i$为原始图像的直方图,
  $Dh$表示直方图h的差分,而$||.||$表示2一范数.


以上介绍的直方图调整方法均是全局处理的,没有考虑图像局部的信息,在确定变
换或转移函数时也是基于整个图像的统计量.且灰度调整的映射一旦确定,原图中的水
平线保持不变,各处相同灰度值的像素点在调整后灰度值仍相同.更复杂和灵活的方法
是根据图像局部的梯度、边缘等特性决定局部对比度增强的程度.


\item 机器色感一致
色感一致性(Color Constancy)No411是人类视觉系统的特性,是指在不同的光照等条件
下,人眼总是能感知到物体的“实际”颜色,而几乎不受光照等条件的影响.
这是由于人眼感知到的某点的颜色和亮度并不仅仅取决于该点进入人眼光线的绝对强度,还和其周围的颜色和亮度有关.
人类视觉系统的这一特性是在其漫长的进化过程中获得的.色感一致性己被一系列的生理学实验所证实.
但通常情况下相机等设备成像的过程则简单得多,只是线性地记录进入到镜头的光照的强度,这样所成的图像就会受到光照条件的影响,在特殊光线条件下会产生色偏(Color Cast)的现象.
用机器计算的方法从已成的图像中估计光照,并提取一致色感的过程称为机器一致色感(Machine Color Constancy)方法.

常见的机器一致色感算法基于以下两种假设之一:白片假设和灰色世界假设.白片(White Patch)假设是指任何一个场景中至少有一处物体是白色的,即亮度达到了可能的最高值,图像其他部分物体的颜色可以此为参照求得.
常见的基于自片假设的方法有基于路径的Retinex,基于二维点随机选取的Retinex(RSR)等.
而灰色世界(Gray World)假设则认为在复杂的场景中,颜色的平均值是灰色,即各种颜色分量的平均值趋于相等,且取亮度范围的中间值.
常见的基于灰色世界假设的方法有基于中心/环绕的Retinex、
自动颜色均衡化(ACE)等.
Provenzi等提出的区域对比度驱动的图像增强方法(RACE)则基于白片和灰色世界两种假设的折衷.
一致色感方法虽可用于去除图像的色偏现象.
但若场景事实上不满足算法的假设,机器一致色感方法就会失败.
若我们用MSRCR算法No1(一种中心/环绕Retinex方法,基于灰色世界假设)处理一幅蓝天占据大部分场景的照片,处理结果中蓝天区域的颜色会趋向于灰色,这是由于场景并不满足灰色世界假设的缘故.
\end{enumerate}


\subsubsection{多曝光融合}
\label{sec:0203}

文献\cite{李艳梅}提出一种基于梯度信息的多曝光融合(Multi-exposure Fusion)高动态范围图像(High Dynamic Range Image, HDRI)合成方法。
为克服通用多曝光融合增强中权值平均等方法中出现的不考虑信息重要性及邻域像素关系所造成的细节损失和模糊等问题,提出依赖于图像曝光质量评估及梯度域信息进行权值设计,对图像进行融合,实验结果表明增强的图像兼具原始图像在暗区和亮区的相应细节,
图像整体效果符合人类视觉感知特性要求。同时提出一种基于分块去混淆(Ghost Removal)的多曝光融合算法。
在处理动态多曝光图像融合增强过程中,最大的问题是如何解决由于运动所产生的混淆现
象。
本文通过提出基于梯度上升优化处理的自适应分块方法,并结合形态学原理,调整分块大小及动态区域块的权值,最终达到混淆去除的目的。
同时利用 Gaussian中心函数窗口滤波,去除在分块融合过程中引入的块边缘不连续性痕迹。
实验结果表明该方法能有效增强多曝光图像并去除混淆问题。

\subsubsection{全景图像拼接}
\label{sec:0204}
\cite{赵书睿}
(1) 研究了图像几何畸变的校正,包括常用的图像几何变换模型、全景图像投
影模型和摄像头失真的校正。引入一种基于几何模型的图像失真校正方法,快速
有效地实现了摄像头失真导致的图像几何畸变的校正。
(2) 分析了基于频域、基于灰度和基于特征的几类图像配准方法。比较了 Harris
角点,尺度不变特征变换和快速鲁棒性特征,确定了比较有效的特征提取方法。
深入研究了特征点提纯和模型变换参数的估计,实现了图像的配准,对手持相机
拍摄的图像的配准也能取得不错的效果。
(3) 针对动态场景中运动物体导致融合鬼影的问题展开了研究,总结现有几种
\textbf{最佳缝合线}的搜索准则,针对它们存在的问题提出了一种改进的最佳缝合线。改
进的最佳缝合线减小了\textbf{曝光差异}的影响并充分利用了相邻像素点间的相似性,同
时提高了算法的速度。研究了多分辨率融合和泊松融合算法,利用傅里叶变换求
解提高了泊松融合的速度。最后利用最佳缝合线与泊松融合实现了自然无缝的全
景图像。

全景图像拼接方法及系统实现
\begin{enumerate}
\item 图像亮度调整
在实际拍摄过程中光照情况完全不变的场景是几乎不存在的,光源的变化,拍摄角度的变化,相机的自动对焦等因素都会导致拍摄的图像间存在曝光差异。
当完成图像的坐标变换后,需要对图像进行一定的处理来减小曝光差异的影响。
图像拼接中最常见的就是对图像进行融合,但是当图像中存在较大的曝光差异时直接融合的效果往往不佳。
这就需要首先根据两幅图像的情况,进行亮度调整来减小图像间的曝光差异。
\item 传统图像融合方法
  \begin{enumerate}
  \item 直接平均法
  \item 加权平均法
  \item 距离权重法
  \item 对比度调制法
  \item 图像融合算法分析
  \end{enumerate}
\end{enumerate}

\cite{张芮}提出了一种新的车牌识别系统的实现方法,使得在各种不同的光照条件下,
通过使用一个具有较大的动态变化范围的传感系统来获取更精确的车牌图像,这个传感
系统是通过对两个不同的\textbf{曝光}条件下的图像进行合成,进而来扩展其动态变化范围的。
为了避免快速行驶车辆所造成的图像模糊,安装了一个相当于多层过滤器的棱形电子束
分裂器,通过调整其入射光与透射光的强度比率来实现图像获取。实验结果表明,提出的
这种系统对于车牌识别是很有效的。

通过合并 ’ 个由不同的 CCD 摄像头在同一时间、不同的曝光条件下所拍摄的两幅图像,那么就可获得一幅具有较大的动态变化范围而无模糊的图像。
这部分主要介绍了该方法,并提出了改进的传感系统的结构。

方法 电子束分裂器将入射光分离成不同强度的反射光和透射光。
分离光线的强度比率$(\lambda_1,\lambda_2)$用光束分裂器内的多层过滤器控制。
不同强度的光线由 2 个CCD 摄像机同时摄入,即传感系统要同时摄入两个不同曝光条件下的图像。

合成两个不同强度的图像后,图像的动态变化范围要比最初产生的图像大得多。
令$\lambda_1>\lambda_2$,
则有下面关系成立:
\begin{equation}
  \label{eq:14}
0 \leq f_2(x,y) \leq f_1(x,y) \leq L_{sat}
\end{equation}
式中 $f_1(x,y),f_2(x,y)$代表通过 CCD1 和 CCD2拍摄的图像上某个像素点坐标$(x,y)$的灰度等级;
$ L_{sat}$ 表示饱和度。
在研究中,来自于摄像机的信号输出数字化为 8 个字节,因而 $ L_{sat}=225$ 。
由$f_1$ 和$f_2$ 具有扩展动态范围的合成图像 $f_{sync}$可通过下面的公式计算出来:

\begin{equation}
  \label{eq:15}
  f_{\mathrm{sync}}(x, y)=\left\{\begin{array}{cl}
f_{1}(x, y), & \text { if } f_{1}(x, y)<L_{\mathrm{sat}} \\
\left(E_{2} / E_{1}\right)^{\gamma} f_{2}(x, y), & \text { if } f_{1}(x, y)=L_{\mathrm{sat}}
\end{array}\right.
\end{equation}

式中, $E_1$ 和 $E_2$是由曝光条件决定的系数,在这里,由于 $\gamma$ 是作为 $gamma$补偿的一个系数,
因此具动态变化的图像,$E_1/E_2$ 的比率应与其中一个摄像机的强度比率
$(\lambda_1:\lambda_2 )$保持一致。
最后,描述了解决密度比率 $(\lambda_1/\lambda_2)$的方法。
传感系统D的动态范围由式~(\ref{eq:16})

计算得出:
\begin{equation}
  \label{eq:16}
D=\left(L_{\mathrm{sat}} / L_{\mathrm{noi}}\right)^{1 / \gamma}\left(E_{1} / E_{2}\right)
\end{equation}

文献 \cite{徐培风}还将BP神经网络应用于自动曝光的图像处理技术中,提出了一种新的
基于图像处理的自动曝光控制算法。
该算法首先将图像分块,将每块予图像的亮度信息作为BP神经网络的输入求出图像的合适曝光量,根据该曝光量确定快门速度和光圈系数,从而有效控制数码相机的曝光。


文献\cite{谢伟}为有效消除引导滤波平滑图像后产生的光晕现象,提出一种新型的融合梯度信息的改进引导滤波算法。
方法该算法借助引导图像的梯度信息来判断图像边缘位置,并结合指数函数框架设计权值来控制不同图像区域内的平滑倍数,使改进后的引导滤波能够自适应地区分和强调边缘,从而避免边缘附近由于过度模糊所引入的光晕现象。
结果与引导滤波算法相比,本文算法能在保边平滑的同时较好地抑制光晕,并在结构相似性(SSIM)评价和峰值信噪比(PSNR)评价中分别取得最高约$30\%$和$15\%$左右的质量提升.

文献\cite{和文娟}分析了 CMOS 图像传感器的模拟噪声类型,主要以时间和空间噪声为分类基础,详细介绍了三维噪声模型的原理。
在此基础上,设计了一个基于三维噪声模型理论的图像传感器时间和空间噪声测量实验。
利用试实验成像系统拍摄一系列均匀背景图像,然后对所拍摄图像进行一系列的分析和处理,得出时间噪声和空间噪声在不同照度下的具体值,并得出其变化趋势。


空间域图像增强
在曝光不足或曝光过度的情况下,图像灰度范围很窄,图像会看起来很不清楚,很多细节看不出来。
灰度变换可以增强原图各部分的对比度,一般采用\textbf{线性变换},
\textbf{分阶段线性变换}和\textbf{非线性灰度变换}三种。
\begin{enumerate}
\item 线性灰度变换

  \begin{equation}
    \label{eq:17}
    \mathrm{g}(x, y)=\left\{\begin{array}{cc}
\frac{a 1}{a 1} f(x, y) & 0 \leq f(x, y) \leq a 1 \\
\frac{b 1^{\prime}-a 1^{\prime}}{b 1-a 1}[f(x, y)-a 1]+a 1^{\prime} & a 1 \leq f(x, y) \leq b 1 \\
\frac{M^{\prime}-a 1}{M-a 1}[f(x, y)-b 1]+b 1^{\prime} & b 1 \leq f(x, y) \leq M
\end{array}\right.
  \end{equation}
\item 直方图均衡化
  在数字图像处理的过程中,灰度直方图是一种非常有效的工具,特别是在图像增强方面应用非常普遍,灰度直方图用来直观统计各个灰度级分布的像素个数。
  我们可以通过分析灰度直方图得到图像的一些特性,在整个图片比较暗的情况下直方图大多集中在低灰度级的一侧,对比度高而色彩丰富的图像灰度直方图布满了整个灰度级且  分布相对比较均匀。


  直方图均衡的基本原理是将原始图像的灰度直方图进行某种变换,增强灰度值的动态范围,使其均匀分布,从而最终达到增强整体图像的对比度的效果。
  可以得到一幅灰度级分布具有均匀概率密度的图像,扩展了原始图像的灰度动态范围。灰度直方图可以用公式 (\ref{eq:18}) 来表示:

  \begin{equation}
    \label{eq:18}
    P_{\mathrm{s}}\left(s_{k}\right)=\frac{n_{k}}{n} \quad \begin{array}{c}
0 \leq s k \leq 1 \\
k=0.1, \ldots L-1
\end{array}
\end{equation}
假定像素点的原灰度级数为 $s_k$ ,经增强函数变换后的灰度级数为 $t_k$ ,需要注意的是 $s_k$ 、 $t_k$ 是归一化后的灰度值,
其灰度变换函数$ EH(s_k )$如公式 (\ref{eq:19})所示:
\begin{equation}
  \label{eq:19}
  t_{k}=E H\left(s_{k}\right)=\sum_{i=0}^{k} \frac{n_{i}}{n}=\sum_{i=0}^{k} p_{s}\left(s_{i}\right) \begin{array}{c}
0 \leq s_{k} \leq 1 \\
k=0,1, \ldots L-1
\end{array}
\end{equation}

MATLAB 影像处理工具箱中有函数 imhist() 可以直接用来显示图像的灰度直方图
\end{enumerate}


文献\cite{刘羽}针对多聚焦图像、多曝光图像、可见光与红外图像、多模态医学图像等多种类型的图像融合问题进行了深入研究,提出了多种变换域和空域图像融合新方法.
空域多曝光图像融合方法研究中,针对传统方法在消除动态场景中运动鬼影能力上的不足,提出了一种基于稠密SIFT描述子的\textsf{多曝光图像融合算法}。
该算法利用特征描述子具有衡量局部对比度和描述局部相似度的能力,将SIFT描述子同时用于多曝光图像细节信息的提取和鬼影效应的消除。
实验结果表明,该算法在主观视觉效果和客观评价准则两方面都可以取得优于传统多曝光图像融合方法的效果。




文献\cite{杨灿}通过分析跑偏测试系统的技术要求,以及跑偏测试系统的使用环境,列
举了三种可能用于行驶跑偏的检测方法。
对比分析传统跑偏测试方式、CCD图像传感器方案、光纤传感器方案及GPS定向测量方案的优缺点,最终确认采用CCD图像传感器方案开发行驶跑偏测试系统。
在此基础上,分析并确定了系统的硬件构成,系统硬件包括图像采集系统硬件、无线通信系统硬件以及相应硬件安装的土建施工等。
在介绍系统硬件部分,文章结合系统要求,对系统各硬件关键技术参数进行了剖析。


硬件
CCD传感器
图像采集 光电开关
系统 环境光传感器
照明系统
无线通信
系统
无线AP
无线交换机
龙门架
土建施工
其它
功能
采集测试图像
产生CCD触发信号
采集环境光强,调节曝光时间
提供夜间测试照明
产生射频信号
集中管理AP,与AP共同构建无线网络,
传输测试指令和测试结果
安装CCD传感器
光电开关支架 安装光电开关
AP支架 安装无线AP
光纤及光纤收发器
连接交换机与AP、连接测试主机与CCD传
感器、连接测试主机与环境光传感器

文献\cite{王燕}介 绍 了在 .NET 平 台 下基 于 OpenCV 图像 处理 库 封装 的 Emg
u CV, 同时 阐述 了它 的特 点及 结 构 ,并对 EmguCV 在 Visual Studio2008开发 环 境 下 的 配置 作 了说 明 。
利 用 MV一3000UC作 为 图像 采 集设 备 ,在 完成 照 相机 的分 辨 率 、曝光和增 益等参数设置的基础上 ,实现 了基于 Emgu CV的视 频或单帧 图像的采集和保存 ,且其性能和易用性较好 。


文献\cite{周望}了一种采用数字微镜(DMD)器件作为sI.M调制面阵CCD的设计方法。
解决普通CCD相机在拍摄高反差场景时,图像上出现过曝光或欠曝光。
造成丢失细节的现象。
该方法通过场景预测成像。
确定CCD按多曝光区域的划定和曝光时问。
利用DMD微镜凋制功能,实现CCD分区分时曝光。
同时设计一种图像数据结构提高了面阵CCD动态范围。
实验证明,该方法不但提高了成像质量,高亮和背光处细节可清晰地表现。而且增强了图像数据的动态范围。
实现r实时获取高动态范围、高质量的图像及数据,不再需要软件“融合”。

文献\cite{付中梁}提出了一种可以对被任意形式的运动所造成的退化图像进行恢复的方法,给出了理论推导,并建立了一套实现系统。
解决了以前的恢复方法存在的只能恢复特定运动形式(如匀速直线运动)的模糊图像的局限性问题。
在主CCD曝光的同时,利用低分辨力的黑白快速CCD获得多帧图像,根据这些图像序列来计算位移,然后求得相对运动的瞬时速度,根据理论分析,点扩展函数和瞬时速度有着对应的关系,进而计算出模糊过程的点扩散函数(PSF),并用来RL迭代法来恢复模糊图像。
实验结果表明,这种恢复方法对任意运动形式造成的模糊,能够得到较好的恢复效果。


\cite{魏伟一}针对目前有关非均匀光照图像灰度校正与分割的基本问题,提出了一些新的参考方法和改进的应用策略,主要创新点有:
1.针对非均匀光照图像的直方图不具备明显的双峰问题提出了光照鲁棒的小波域
灰度拉升与快速的阈值化分割方法。
2.对于图像灰度不均匀场的建模分析与校正中,研究了非均匀光照的表示模型,采用了Retinex模型和基函数表示非均匀光照的思想,利用曲面拟合与表示的数学方法,用正交基函数的线性组合来表示非均匀光照,从而建立了非均匀光照场的表示模型和快速的参数求解方法,实现了基于能量最小化方法的光照非均匀图像的自适应校正,可以对图像在分割前进行有效的预处理
3.在基于PCNN方法的图像分割中,首先针对非均匀光照环境的特性实现自适应确定
PCNN模型的部分参数,充分考虑人眼的视觉特性,利用像素的对比度设置模型中的内部
活动项连接强度p值、像素邻域信息的相关性确定连接矩阵IV的值,不仅考虑了像素之
间的距离因素,还结合了像素间的灰度差异,其次充分考虑了图像的空间结构性上的几
何信息而采用了以图像的区域互信息熵作为PCNN分割方法迭代终止条件的判决依据,从
而提出了光照鲁棒的参数自适应确定的PCNN图像分割,解决了传统PCNN方法对于非匀光照导致的灰度不均匀图像分割效果不好的问题。
4.提出了同步估计非均匀光照的FOI图像分割方法。
5.在非均匀光照影响较大的彩色细胞图像的分割中,提出了光照鲁棒的基于主成分分析的分割方法。

\subsubsection{非均匀光照图像灰度校正的研究现状}
\label{sec:0205}
图像增强的主要目的是增强图像中的细节信息,校正照度不均匀导致的图像中的灰度不均匀现象。
然而图像增强与感兴趣物体的特性,观察者的习惯等因素密切相关,具有很强的针对性和主观性,因此实际中并不存在一种通用的、适应各种应用场合的图像增强算法。
目前照度不均匀图像的灰度不均匀校正与增强方法主要有以直方图均衡化方法为代表的灰度变换法、直方图修整方法、图像空域上的灰度变换法、基于同态滤波的图像灰度校正与增强方法、基于照明一反射模型的Retinex增强方法、梯度域增强方法以及基于参考标样的灰度校正方法。
\begin{enumerate}
\item 直方图变化方法为代表的灰度变换法
  用直方图变换方法进行图像增强时主要以概率论为基础,是图像增强最常用到的最重要方法。
  该方法主要是指通过构造灰度级映射变换,改造原始图像的直方图,从而使变换后图像的直方图达到一定的应用要求,使得原始图像灰度级集中的区域被拉开或者使灰度分布均匀的区域增大对比度,使图像细节更加清晰,来达到图像增强的目的。
  用直方图变换方法进行图像增强时又包括直方图均衡化和直方图规定化。
  直方图均衡化主要用于增强动态范围偏小图像的反差,是使变换后的图像灰度分布趋于均匀而对各像素点进行灰度变换的一种均衡化调整方法。
  也就是把一个已知灰度概率分布的图像,经过一种函数变换,使之转变为一副具有均匀概率分布的新图像。
  直方图均衡化的理论依据是当图像的直方图为均匀分布时,它的信息熵达到最大值,此时的图像含有的信息量最大,图像看起来最为清晰。
  这种方法对于一些灰度分布比较密集或者对比度较低的图像可以取得比较满意的增强效果,但是该方法仅仅使图像灰度级分布平均化而不是扩大灰度范围,对于灰度级分布范围较大的图像灰度拉伸效果不明显,并且会产生灰度级合并的现象,表现为处理后的图像亮度被过度提升,而且处理的结果只是得到全局均衡化的直方图,从而将改变图像的原始面貌并丢失图像的细节信息。
  在实际应用中,有时希望能够有目的地增强某个灰度区间的图像,即能够人为地修正直方图的形状,使之与期望的形状相匹配,这就是直方图规定化的基本思想。
  因此图像直方图规定化就是为了满足在实际应用中有时变换直方图使之成为某个特定形状的需要,通过选择规定化的函数来有选择地增强某个灰度范围内的对比度或使图像灰度值的分布满足特定的要求。
  直方图规定化是在运用均衡化原理的基础上,通过建立原始图像和期望图像之间的关系,有选择地控制直方图,使原始图像的直方图变成规定的形状,从而弥补了直方图均衡不具备交互作用的特性,但是正确选取规定化函数是获得比直方图均衡化更好效果的关键。
\item 图像空域上的灰度变换方法
  图像的灰度变换是一种利用逐点运算改变图像像素灰度值的简单实用的图像增强方法,在图像处理中也被称为查找表。
  灰度变换中的点运算是指把输入函数$f(x,y)$的每一点依据函数法则进行咖映射,即输出灰度分布.
  \begin{equation}
    \label{eq:20}
g(x,y)=\phi f(x,y)
\end{equation}

式中的映射咖可以是线性、分段线性或者非线性等多种形式的函数,其函数表达式为
$\phi(f)=af+b$.
除了单段直线变换外,还可以有多段直线变换、非线性变换(如对数变换或指数变换)。
具体对应的处理可以有图像求反、增强对比度、动态范围压缩和灰度切分等方式,一般都根据原始图像的实际情况及其所需图像的要求来选择变换,如摄像元器件由于具有非线性特征而选择利用与$45^0$线段对称的变换曲线进行灰度校正。
\item 基于同态滤波的图像增强方法
  同态滤波是图像预处理中的一种常用方法,主要用于解决光照非均匀图像的灰度校正问题。
  它是把频率过滤和灰度变换结合起来的一种图像处理方法,主要利用图像的照度一\textbf{反射分量模型}作为频域处理的基础,通过压缩亮度范围和增强对比度达到改善图像的质量。
  在基于同态滤波进行图像灰度不均匀校正和增强的方法中,将图像视为入射分量
  $i(x,y)$和反射分量$\gamma(x,y)$的乘积:
  \begin{equation}
    \label{eq:21}
    f(x,y)=i(x,y)\times\gamma(x,y)
  \end{equation}


其中入射分量$i(x,y)$均匀缓慢变化,频谱集中在低频段,而反射分量$\gamma(x,y)$则主要
反映了图像的细节特性,频谱主要集中于高频区域。

如果图像存在照度不均匀,则图像上各部分的平均亮度会有起伏,对应于暗区和高亮区的图像细节结构就较难分辨。
因此,要消除这种灰度不均匀性,可以在频域上减弱照明函数的成分,同时增强反射函数的频谱部分,使图像上该区域的图像细节得以增强。

在基于同态滤波的增强方法中,是将两个分量的乘积通过对数运算转换为加法运算,然后利用傅里叶时频变换方法,再设计合适的滤波器,来加强高频分量,同时削弱低频成分,从而达到克服非均匀光照,压缩动态范围与增强对比度的目的.

算法中的滤波器函数$H(u,v)$又被称为同态滤波函数,它可以分别作用于入射分量和反射分量上。
图像的照射分量通常以空间域的缓慢平滑变化为特征,而反射分量往往引起突变,特别是物体的边缘部分,这些特点使图像的低频跟照射分量相联系,而高频部分和反射分量紧密联系。
因此算法的关键是设计一个对傅里叶变换的高频和低频分量影响不同的滤波函数$H(u,v)$,一般常选取高斯型同态滤波器进行滤波控制。


在基于同态滤波的图像灰度不均匀校正和增强方法的关键是将公式1.2中的照射分量和反射分量通过对数域转换由乘性变换为加性,从而有利于滤波处理。
基于同态滤波的图像增强和灰度校正可以在增强高频信息的同时保留低频信息,达到压缩灰度的同态范围,增强图像对比度的效果。
对于那些因照度不良导致的图像亮度不足和细节模糊,信噪比较低的图像,增强效果显著。但是,在同态滤波频域算法中需要两次进行傅里叶变换,占用较大的运算空间,实时性不高。
\item Retinex图像增强方法
  Retinex算法最早由Land提出的解释人类视觉系统(HSV,HumanVisual System)如何调节感知物体的颜色和亮度的模型,它的基本思想是人眼感知到某点的光照不仅取决于该点反射出的绝对光照值,还和该点周围反射出的光照值密切相关。
  Retinex算法实质上是一种基于\textbf{光照补偿的图像增强算法},由于它成功揭示了人类视觉系统的众多基本特征,并以颜色恒定性为出发点,同时又具备了高动态范围压缩的能力,因此被广泛用于航拍图像和医学图像的增强处理中。


  Retinex算法经过不断发展已经成为真彩图像增强的最出色算法之一,因此在实际应用中具有极其重要的地位。
  在Retinex算法的基本模型中,认为图像由亮度图像和反射图像构成,在此分别用
  $L(x,y)$和$R(x,y)$表示,三者的关系可由式~(\ref{eq:22})来表示:
  \begin{equation}
    \label{eq:22}
I(x,y)=L(x,y)\times R(x,y)
  \end{equation}
式中,$L(x,y)$是亮度分量,表示被观察者或图像捕捉设备收到的构成图像,反射分
量$R(x,y)$决定了图像的内在性质。

Retinex方法对图像处理的目的就是从图像$I$中获得物体的反射性质分量$R$。
它的一般步骤是先从原始图像中估计出光照,然后在对数域中从原图减去光照图像得到增强后的图像。
在Retinex增强方法模型中,非均匀光照体现在入射分量中,它基本上是属于变化较缓慢的低频成分。
而图像的细节、反差等特性则主要由图像中物体本身的特性决定,它反映在图像的反射分量中.
将二者的乘法组合通过对数处理变成加法运算组合,然后进行傅里叶频域变换,依据入射分量与反射分量所表征的图像性质,设计出一个合适的滤波器,使得低频成分削弱,高频分量适当增强,从而达到克服非均匀光场,压缩动态范围与增强对比度的目的。
但是,Retinex方法重建的光照图像是通过对全局平滑得到,所以阴影边界附近被严重模糊而产生光晕伪影,此外,反射率图像的重建依赖于光照图像,使得对应区域的反射率图像的细节和颜色产生扭曲,同时,算法还涉及大量的时频转换时间开销,所以非均匀光照图像的灰度校正与分割技术研究并不适合工业视觉在线检测系统。
\item 梯度域增强方法
  图像在拍摄时的照度不均匀导致的图像灰度不均匀在梯度场中则表现为梯度的不均匀分布。
  一般图像的对比度高则梯度的强度大,结构比较清晰,因此可以通过扩大图像的梯度范围以增强图像的动态范围,即通过处理图像梯度场来校正图像获取时照度不均匀导致的灰度不均匀现象。
  梯度域增强方法是对原始图像的梯度域进行处理,通过减小图像梯度值来压缩图像的动态范围,通过增大图像局部梯度值来增强图像的边缘。
  Subr等提出了一种利用图像局部差分综合的目标函数来度量图像对比度,并通过贪婪迭代优化方法实现目标函数的最大值来校正图像的灰度不均匀。Fattal等人则提出了直接对图像梯度进行修正的方法,将图像转换到对数域中并求取图像梯度值,将某一因子作用于每个梯度图像的像素中,来减弱其梯度值,然后在梯度域重建图像数据并指数化输出。
  也可以直接在图像梯度域中对梯度函数使用直方图均衡化方法取代因子,以此来增强图像局部对比度的同时使图像整体梯度均匀化,避免了使用Retinex方法产生晕环的现象。
图像梯度增强方法能较好地保持原图中的细节信息和层次感,适合于分析图像的高光和阴影区域信息,缺点是会导致图像在一定程度上产生出锐化效应,并且在梯度域中重建图像时需要一定的数值计算方法,不适合于实时性场合的应用。

\item 参考标样法
基于参考标样的图像灰度不均匀校正的方法是先对具有均匀分布的完全不受光照
影响的标样(比如干净均匀的白纸)进行成像,然后利用所获得的标样作为标准参考值来对实际图像进行灰度调整。
这种图像增强与灰度校正的方法主要被应用于光照不均匀环境下获取的图像,或者图像获取设备中的感光元件有差异而造成的图像灰度不均匀的场合,但是对于一些图像获取环境复杂造成的灰度不均匀或者对比度发生很大改变的图像,增强与校正效果不是很理想。
例如在近距离成像环境下,由于点光源光照的不均匀性以及光源距离物体的位置不断变化等因素都将导致标样图像的不可参考性与局限性,使得该方法无法满足灰度不均匀图像的自适应增强与灰度校正的要求。
\item 彩色图像中的灰度不均匀校正
  在图像的自动分析过程中,彩色是一种能简化目标提取和分类的重要参量。
  对彩色图像处理的关键问题是如何选择合适的彩色模型。
  一般常用的彩色模型是RGB模型,但由于在人眼视觉的特性中,亮度分量与色彩分量是分开的,并且色调和饱和度与人的视觉感知是紧密相连的,因此在彩色图像处理中常采用HSI模型。
  由于照度不均匀主要体现在图像的亮度信息中,因此对于彩色图像的灰度不均匀的校正,一般都是通过将图像从RGB空间转换到HSI模型中,对含有亮度信息的1分量利用灰度图增强校正的方法处理,再将结果转换为RGB空间。
  在图像的HSI空间进行图像灰度校正与增强,并没有改变原图的彩色内容,但由于亮度分量得到了校正与增强,整个图像会比原来更亮一些。
\end{enumerate}


文献\cite{马明}提出的方法是由运动模糊图像本身估计系统的点扩散函数。
在摄取图像的短暂曝光时间内,造成图像模糊的运动可近似作为匀速直线运动处理。
而匀速直线运动模糊是动态情况下的一种典型模糊,因为变速的、非直线的运动在某些条件下可以看成是匀速的、直线运动的合成结果。
将原始图像视为各向同性的一阶马尔科夫过程,利用双线形插值和构造出的3x3方向微分乘子,采用“先租后细”的方法,粗略确定运动模糊方向范围后,再高精度鉴别其具体数值。再将模糊图像旋转到水平轴,则二维问题简化为~维问题。
利用模糊图像的模糊度内的像素点之间的相关性估计模糊尺度。
有了运动模糊方向和尺度这两个参数后就得到了点扩散函数,然后可用滤波的方法恢复出原始图像。


\subsubsection{复杂环境中交通标识识别与状态跟踪估计算法研究}
21世纪初以来,许多研究者和汽车制造商均在无人驾驶车技术的研究与开发投入了大量人力和物力。
其中一个重要研究内容是基于计算机视觉的道路环境感知:识别车辆行驶道路周边的交通标志信息和交通信号灯状态,为无人驾驶车行驶提供决策依据。
在国内外已有的交通标识检测,识别,跟踪和状态估计方面的研究成果基础上,结合交通标识系统在无人驾驶车上的实际应用和测试性能,设计并构建了面向无人驾驶车的交通标识实时检测,识别和跟踪的算法和系统。

文献\cite{谷明琴}介绍了相机的成像过程,根据相机CCD的原始参数及标定的相机内参数,估计出道路环境中交通标识与车载相机间的近似距离与角度。
为了控制相机的曝光时间,调节图像亮度,需预先判断交通标识出现区域的亮度信息和曝光量,根据曝光情况选择不同的权值矩阵,计算出最佳曝光时间。
该方法能准确地调节相机的曝光时间,以采集到亮度合适的图像,适合于交通标识的检测与识别处理。

提出了50类符号型以及多种文字型的交通标志的检测与识别算法。
变换RGB空间图像,突出交通标志的特征颜色(红色,黄色,蓝色),选择合适的阈值分割图像。
重构形态学处理后的交通标志感兴趣区域边缘,降低误检率。
选择形状的标记图特征以分类感兴趣区域的形状并排除干扰。
对文字型交通标志,则用阈值分割图像中的墨绿色和蓝色区域,判断区域的形态,选择矩形区域作为交通标志候选。
将候选区域的二值图像先向水平,后向垂直方向投影,用三次样条插值法拟合该投影曲线,定位曲
线的波谷,确定文字的行和列位置,以分割出单个文字区域。
用两种模型表示方法:(1)二元树复小波变换和二维独立分量分析方法;(2)基于内部图形的模板匹配分别识别候选区域的交通标志类型,然后用决策规则融合两种方法的识别结果,并排除干扰区域。
实验结果表明交通标志的识别率超过91\%,平均处理时间为171ms,所提出的交通标志识别算法性能优越,适合应用于\textbf{无人驾驶车辆}的环境感知系统。
提出了箭头型和组合型交通信号灯的检测和识别算法。
对于箭头型交通信号灯,根据灯板和信号灯的颜色和形态特征,定位出图像中的灯板及交通信号灯位置。
对于组合型交通信号灯,则先将图像进行TopHat变换,然后将其从RGB空间转换到YCbCr空间,并进行阈值分割和形态学滤波。
根据区域的宽高,面积,占空比等形态信息初步过滤。
组合感兴趣区域,向水平方向投影,根据波谷位置定位单个交通信号灯区域。
将候选区域灰TT度化,归一化,提取Gabor小波特征,用2维独立分量分析方法降低特征的冗余度,送入最近邻分类器以判断交通信号灯的状态。
在3个城市内采集了大量的视频,测试了算法性能,综合性能表明该算法的总体识别率在91\%以上,平均处理时间为152ms,能实时,稳定,准确的识别交通信号灯。
构建了交通标志的多目标跟踪模型,定义了交通标志目标的状态。
用无迹卡尔曼滤波算法建立单个交通标志目标的状态和运动轨迹模型,预测交通标志目标的位置。
而对交通信号灯,则用Kalman滤波跟踪交通信号灯的灯板和灯区域。
选择观察序列训练单个和三个交通信号灯目标的隐马尔科夫模型参数,用隐马尔科夫模型算法估计交通信号灯下一时刻的状态信息。
建立了交通标识识别系统的实验平台,设计和实现了交通标识识别的两个子系统:(1)交通标志识别系统;(2)交通信号灯识别系统。
详细描述了系统的功能,显示形式,参数设置等。


无人驾驶车的实时感知道路交通标识是无人驾驶的核心问题之一。
本论文研究城市内,动态场景中交通标识的快速定位与识别方法。
在车辆行驶过程中,对道路环境中出现的多种交通标识进行采集,检测,定位,识别及跟踪,可为无人驾驶车提供及时准确的道路环境信息,以遵守交通规则安全行驶。
借鉴\textbf{人类视觉认知机理}、\textbf{计算机视觉},\textbf{图像理解与分析},以及\textbf{模式识别理论}的最新研究成果,研究和设计快速、自动、鲁棒的交通标识识别系统,为无人驾驶车的相关理论与应用发展提供有力的支持,具有重要的理论意义和实用价值。


国内外学者已进行了多年交通标识的检测与识别研究,取得不少进展及成果,但由于交通标识所处的环境复杂,干扰较多,不可避免地存在许多困难,主要有以下几个方面:

(1)光线因建筑物,树木遮挡,图像中的交通标识成像光照不均匀,色彩差异严重;

(2)不同时刻的光照,不同天气条件都对图像的色彩,亮度产生重要影响,特别是黄昏或清晨,太阳偏低,容易在图像中产生光晕,偏色,且容易使表面平滑的交通标志产生镜面反射;

(3)长期的阳光照射,与空气中物质的化学反应,交通标识表面有灰尘覆盖,都会使交通标识色彩受损或被污染,造成拍摄图像中的交通标志昏暗,降质:

(4)交通标识的形状结构比例,拍摄角度,距离,位置,背景等差异,都会导致交通标识出现几何失真和形变;

(5)由于汽车的高速行驶造成的相机抖动及相机本身性能影响,获得的图像产生模糊或抖动,严重影响交通标识识别的准确性。

因此至今未有在实时性、准确性、适应性等方面均能取得较好效果的交通标识识别系统。解决该问题涉及到图像处理、图像理解、计算机视觉、人工智能、光学等大量知识,因此在复杂动态场景下进行交通标识的检测与识别,是一个值得研究的课题。

在车辆行驶的道路环境中,交通标志与周围环境差异明显,它具有特殊的颜色(红色,黄色,蓝色,绿色等),形状(圆形,三角形,方形,矩形等)和图形(箭头,数字,字符等)信息。
在已发表的文献和研究成果中,交通标志的识别系统主要分为两个阶段:
(1)交通标志检测:从复杂道路环境采集的图像中,根据交通标志的颜色和形状特征,寻找和定位交通标志的感兴趣区域。
(2)交通标志识别:对交通标志的感兴趣区域,用不同的方法提取感兴趣区域的特征,用合适的分类算法分类这些感兴趣区域,得到交通标志类型信息。


\begin{enumerate}
\item 交通标志检测
  \begin{enumerate}
  \item 颜色聚类和形状分析:不同颜色空间中分割图像,并分类出不同的交通标志;
  \item 特征聚类;
    除颜色分割外,其它一些研究者则采用了颜色特征聚类算法。
    Bahlmann等用对颜色敏感的Haar小波特征检测交通标志,结合AdaBoost训练和时空信息传播特性来提取特征,用时空假设融合的贝叶斯生成模型分类交通标志。
    然而,该算法需要大量的训练图像,时间复杂度较高。
    为了避免特征空间维数过大,使boosted分类器失效,Baro提出了一种改进的AdaBoost二值分类器。
    误差纠错输出代码中嵌入优化树结构的多类型学习技术识别交通标志。
    Escalera利用Adaboost与方向修正的径向对称算法来进行初始检测,然后用归一化k-最近邻域来分类。
    然而其过于侧重弱分类。
    Ruta等用图像表示和判别特征法来识别道路标志。
    然而该算法会过度搜索特征集,训练时间会随特征数量的增加而上升。
  \item 度图像交通标志检测。
  \item 文字型交通标志检测
    一些道路交通标志中含有一些文字内容,提供指示,方向,限制信息。
    Wu等提出了一种基于特征的检测交通标志文字的方法。
    用颜色分布和几何约束来寻找稳定的特征点,在这些特征点检测算法中使用了垂直面准则。
    文献提出用滑动同心窗口的方法来定位道路交通标志中的文字。
    但上述算法检测速度较慢,无法应用到智能车载系统当中。
    Gatos等设计了一种自然场景中的检测文本的方法,先对图像进行二值化并增强,然后分析合适的连通区域。
    Chen等提出用多尺度和多分辨率的LOG(Laplacian ofGaussian)边缘检测子,自适应搜索,颜色分析及仿射矫正算法来检测处理不同大小,方向,颜色分布,和背景的文本,用OCR(Optical Character Recognition)识别文字内容,并将其翻译成英文。
    文献构建了一种在灰度图像上检测并定位文本的复杂系统,该系统将集成特征和弱分类器的boosting框架来构建有效的文本检测子。
    提出用较小的超像素特征集,组合为一个大的特征集。该算法可定位复杂背景中字体和大小差异明显的文字。
  \end{enumerate}
\item 交通标志识别
  \begin{enumerate}
  \item 特征提取
    交通标志的含义由内部图形定义,如指示性箭头,特定的符号或图形等。
    可以用一些特征表示交通标志如:\textbf{Tchebichef不变矩},\textbf{SIFT特础},\textbf{Gabor小波}等。
    Ruta等利用\textbf{感兴趣区域的关键局部特征和颜色距离变换}来识别交通标志。
    Gao等用\textbf{局部边界走向和任意固定点到对应顶点密度的49维特征向量}来分类交通标志,文
    中指出其识别率可以达到95\%。
    然而,这些特征是人工选择,可信性较低。
    Cai等\textbf{融合二元树复小波变换和2维独立分量分析法},提取交通标志的特征,采用最近邻分
    类法对其进行分类。
    该算法具有较高的识别率,较强的实时性。
  \item 交通标志分类
    \begin{enumerate}
    \item 模板匹配
      Piccioli等用\textbf{基于未知交通标志的灰度图和数据库中的目标的相似性度量}。
      其分类率达到98\%,数据库中包含60个圆形标志和47个三角标志。
      Zadeh等融合感兴趣区域的面积比和模型匹配来识别交通标志。
      此种方法对旋转和区域大小的尺度不变,有助于减少匹配的模型数目。
      他们同样分析了感兴趣区域中水平和垂直的颜色面积比,来寻找不同交通标志中包含相似特征颜色比之间的差异。
      Hsu等用\textbf{模板匹配方法}获得超过85\%的正确分类率,数据库包含30个三角形标志和10个圆形标志。
      该方法对旋转和区域面积具有尺度不变性,利于减少匹配的模型数目。
      分析了感兴趣区域中水平和垂直的颜色面积比,统计不同交通标志中包含相似特征颜色比之间的差异。
    \item 神经网络
      Fang等介绍了在视频中识别交通标志的动态视觉模型,开发了两个神经网络,从色调分量和梯度图像中提取颜色和形状特征,定位交通标志,使用卡尔曼滤波序列来进行跟踪。
      Estable等用径向基神经网络对图形进行识别。
      Hossain等在RGB空间进行颜色分割,选择Hu不变矩作为特征,用神经网络进行交通标志识别。
      这些识别算法对分割完整的标志比较有效,而在动态交通标志快速识别中,分割出的候选区域过大或过小,令识别的准确率下降或识别算法失效,且实时性不强。
    \item 支持向量机
      Huang等在Lab空间中分割图像,用改进的快速径向对称子检测圆形区域,PDH图形分布直方图作为分类特征,用支持向量机进行分类与识别。
      方案判断光照条件,利用Adaboost分类方法检测交通标志的候选区域,用支持向量机识别。
      文献使用基于决策树的多层支持向量分类器进行交通标志识别。
      Bascon等把候选的交通标志归一化并转换为灰度图像,用多种图像增强方法增强其差异性,用改进的支持向量机识别增强后的交通标志区域。
    \item 其它的分类算法
      Douville用多层感知网络训练快速傅立叶变换和感兴趣区域滤波器组的数据,比较了模板匹配和统计模式识别算法的效果,该方法的效果较好,但与其它识别算法的结果相比,依然具有一定差距。
      Paclik等介绍了一种新颖的分类策略:与存储模板图像相似的特征来表示候选标志。
      对训练提取的不同局部特征进行不同类别间的相似性度量。
      对相似性较低的标志类型,这种方法非常有效。
      而文献[27]用\textbf{具有Laplace核分类器的级联分类系统识别交通标志}。
      与单一分类算法相比,该系统可以识别较多的交通标志类型,虽然识别的误差率较低,然而该系统的分类率高低过于依赖图像的颜色分割效果。
      Deng等提出了一个交通标志识别系统的新框架,\textbf{利用稀疏模式的字典学习方法来收集交通标志信息}。
      Khan等提出\textbf{融合颜色特征聚类和形状分析来检测交通标志,用畸变不变性的联合变换相关性}来分类。
      该算法对平移、旋转、尺度、局部遮挡具有不变性,但识别速度非常慢。
      文献首次在广角图像中用颜色,强度和形状信息,检测交通标志的感兴趣区域。
      识别算法使用了已有的图像处理板中的内置函数。
    \end{enumerate}
  \end{enumerate}
  \end{enumerate}

\subsection{KITTI数据集}
\label{sec:03}

\subsubsection{面向移动机器人视觉导航的三维环境重建技术研究}
\label{sec:0301}
文献\cite{黄丽}采用基于图像特征点的方法,主要包括图像匹配、运动轨迹求解、环境三维重建三大部分。
在第一部分中,对运动过程中相机获得的二维图像进行SIFT特征匹配,通过本质矩阵求解相机的旋转和平移矢量,获得相机的外参矩阵,同时对SIFT和ORB算法进行了对比。
为了获得更好匹配关系,增加了误匹配剔除过程,并对RANSAC算法做出了改进,降低了算法的执行时间,保证了匹配正确率。
对于单目所存在的尺度问题也进行了详细的说明。
在轨迹求解部分,采用增量式方法根据相机的外参矩阵得到运动轨迹,最后为了解决因累积误差所带来的轨迹漂移问题,加入局部回环,采用图优化方法,利用920库实现Bundle Adjustment捆集优化。
在三维点云重建部分,通过三角测量法获得三维空间点坐标,然后利用PCL点云库进行可视化,得到了稀疏的点云三维模型。
为了使点云模型可视性更强,引入了PMVS算法,建立相对稠密的重建。

视觉三维重建
\begin{enumerate}
\item 视觉三维重建理论体系
\end{enumerate}


\section{点云}

\subsection{一种基于注意力机制的三维点云物体识别方法}
\label{sec:01}


文献\cite{钟诚}
三维点云数据通常具备无序排列的结构。
在三维点云数据处理领域,深度学习模型通常会利用最大池化等对称操作来处理点云的排列不变性。
最大池化方法一方面会破坏点云的信息结构,使得局部信息与全局信息难以交互。
另一方面,最大池化方法对点云信息过度压缩,得到的特征对局部细节描述不足。 针对上述问题,提出了 AttentionPointNet 的
网络结构。 该网络利用注意力机制,使每个点与点云其余部分进行特征交互,实现了局部与全局信息的综合。 为降低最
大池化造成的信息损失,提出了一种稀疏卷积方法来替代池化操作。 这种方法利用大步长的稀疏卷积实现全局信息的提
取。 在 ModelNet40 数据集上,AttentionPointNet 取得了 87. 2\% 的准确率。 不使用池化层,完全采用卷积层实现的模型取得
了 86. 2\% 的分类准确率。

\subsection{点云}
\label{sec:03}

\subsubsection{点云基本理论}
\label{sec:04}

点云是某个坐标系下的点的数据集，包含了丰富的信息，可以是三维坐标X，Y，Z、颜色、强度值、时间等等。
下面的图表分别展示了点云在三维空间可视化以后的效果和数据格式。
点云的数据获取方式有很多种，比较常见的是三维激光扫描仪进行数据采集，它有三大类：
    星载（星载LiDAR采用卫星平台，运行轨道高、观测视野广，基本可以测量到地球的每一个角落，为三维控制点和数字高程模型的获取提供了新的途径，有些星载激光雷达还具有观察整个天体的能力）
    机载：机载主要借助无人机（UAV/UAS）进行大规模的点云数据采集。
    地面分为三小种：地上三维激光扫描、车载MMS、手持激光扫描。

avatar
x       y       z
0.07388         0.16975         -0.19326
0.15286         0.15050         0.24355
0.18606         0.15050         0.29081

从上面的数据示例可以看出，点云本质上是一长串点（Nx3矩阵，其中n是点数），这带来两个问题。
第一，在几何上，点的顺序不影响它在空间中对整体形状的表示，例如，相同的点云可以由两个完全不同的矩阵表示，如下图所示。我们希望不论点云顺序怎样，模型可以从中得到相同的特征。
第二，点云在空间中经过刚性变换后，如旋转或者平移，点云的坐标会变。
有时我们为了方便对点云做处理（如分类等），需要将其旋转到正面或者侧面（做旋转），此时，模型得到的点云数据（N*3矩阵）将会完全不同。
我们希望点云做变换之后不会影响模型的结果。
传统的点云处理方式包括两大类：
将点云数据投影到二维平面。
此种方式不直接处理三维的点云数据，而是先将点云投影到某些特定视角再处理，如前视视角和鸟瞰视角。
同时，也可以融合使用来自相机的图像信息。
通过将这些不同视角的数据相结合，来实现点云数据的认知任务。
比较典型的算法有MV3D和AVOD。
将点云数据划分到有空间依赖关系的体素（voxel）。
此种方式通过分割三维空间，引入空间依赖关系到点云数据中，再使用3D卷积等方式来进行处理。
这种方法的精度依赖于三维空间的分割细腻度，而且3D卷积的运算复杂度也较高。

接下来我们会介绍从17年至今比较经典的关于点云的论文，包括PointNet，PointNet++，GeoNet，Kd-Net、SO-Net以及做数据上采样的PU-Net。
此处是PointNet的位置
此处是PointNet++的位置
    论文名 GeoNet: Deep Geodesic Networks for Point Cloud Analysis
    作者 Tong He，Haibin Huang，Li Yi等

    GeoNet是一种基于测地距离的点云分析深度网络，发表在2019年的CVPR上。论文贡献包括两个：开发了一种数据表示以及提出了如何将其运用到下游任务中的方法。
    为了方便理解论文内容，我们首先来介绍一下测地距离这个概念。
测地距离
我们先从点云的研究任务说起。
点云的形状分析是点云的重要任务之一，主要包括三个方面的特征，集合特征、统计特征和拓扑特征。
集合特征主要有法向量、曲率等，统计特征主要包括模型顶点间的集合关系、顶点的曲率分布等，拓扑特征主要有突出的特征点、临界点、骨架、Reeb图等，其中骨架是对点云主要特征的一种可视化描述，符合人类的视觉特征。
从目前已有的工作来看，拓扑特征是点云的重要特征之一，对点云的分类、简化、检索等研究有重要的作用。
寻找提取点云拓扑特征的简单、有效、快速的方法对点云的形状分析与理解具有重要的意义，测地线就是其中的一种。
测地线是连接曲面上给定的两点之间的最短路径，测地线的长度就是这两点之间的测地距离。
根据计算结果的精确性，三维模型的测地距离的计算方法可以分为两大类：精确的方法和近似的方法。
可以看做是图论上计算两个点之间的最短路径的计算方法，采用dijkstra等。
GeoNet计算测地距离
GeoNet其实就是利用网络来计算测地距离。
我们假设χ={xi}表示点云，每个点的维度为3 。
那么我们可以为点xi定义它的邻居节点为Br(xi)={xj|dE(xi,xj)≤r} 。
其中dE(xi,xj)表示两个节点之间的欧式距离。
也就是说将xi为球心，半径为r内的节点划为它的邻居节点。
这是GeoNet关于邻域的定义。
基于此我们继续定义Gr(xi)={gi,j=dG(xi,xj)|xj∈Br(xi)}，其中dG表示测地距离，即Gr(xi)表示 xi到邻域内每个点的测地距离的集合。
GeoNet的目标是利用神经网络拟合映射关系：f:xi→Gr(xi)，它的网络结构如下图所示。

如图所示，GeoNet由两个模块组成：特征提取模块以及测量匹配模块。
其中特征提取模块利用PointNet++提取点云的局部特征，再将其输入解码器，同时还将原始的点云输入解码器（skip connection），这样解码器可以对点云的局部特征和总体特征做处理。
测量匹配模块利用特征抽取模块得到的特征向量为每个节点计算其邻域测地距离。
但该模块的目的并不是计算出准确的测地距离，而是在模型不断拟合测地距离的过程中，其参数矩阵会隐含的提取出一些特征。

（笔者私以为，GeoNet的作用就是进行特征提取，在训练模型计算测地距离的过程中，模型的参数包含了点云的一些特征）

论文中还详细介绍了GeoNet如何与下游任务：分类、分割等做融合，并给出了示例。
Kd-Net#
    论文名 Escape from Cells: Deep Kd-Networks for the Recognition of 3D Point Cloud Models
    作者 Roman Klokov,Victor Lempitsky

Kd-Net是一种基于Kd-tree的网络，我们先对Kd-tree加以介绍。
Kd-tree#

KD树是从二叉搜索树发展来的，是一种高维索引树形数据结构，常用于大规模高维数据密集的查找比对的使用场景中，主要是最近邻查找以及近似最近邻查找，在CV中主要是图像检索和识别的高维特征向量的查找和比对。
我们举例讲述如何构建一个三维的KD树。
我们可以在第一层选择用节点的第一维数据作为分类依据，第二层用第二维数据，第三层用第三维数据，第四层用第一维数据，以此类推。用图中的数据来说明：
    根节点为（3，1，4），分类依据为3。
    拿到第二个数据（2，3，7），先与根节点（3，1，4）比较，第一层节点的分类维度为一，（2，3，7）的第一维数据小于根节点的第一维数据，所以下一步与根节点的左节点做比较，发现左节点为空，将（2，3，7）放在左节点。
    拿到第三个数据（2，1，3），先与根节点（3，1，4）比较，第一层节点的分类维度为一，（2，1，3）的第一维数据小于根节点的第一维数据，所以下一步与根节点的左节点做比较。左节点为（2，3，7），第二层节点的分类维度为二，（2，1，3）的第二维数据比（2，3，7）的第二维数据小，下一步与其左节点作比较。左节点为空，将（2，1，3）插入该点。

    KD树构建过程

    二维KD树的表示方法

利用Kd_tree构建Kd-net#

了解了如何构建Kd-tree后，我们来看如何根据点云构建Kd-tree进一步组成Kd-net。
下图左边是建好的Kd-tree，编号为8-15的是8个数据点。
可以看到紫色的是第一次切割，蓝色和红色是第二层，绿色和橙色（或红色？）是第三层。
该示意图用二维展示了三维点云的kd-tree，在三维空间中，切割的方向是x,y,z轴。
为了将点云向量化，作者先用预训练好的数据将叶子节点（8、9、12、13、14、15）向量化，然后根据公式逐层向上计算每个节点的向量表示，直到所有的节点都被向量化。
图中的右半部分是Kd-net的结构图，其中灰色的条表示网络的节点，中间的圆圈是网络的参数，第一层是所有数据点的向量表示。
网络经过一次前向传播得到一个特征向量，即图中标号为1的节点，该节点提取了所有数据的特征。
标号为1的特征向量经过一个全连接层得到节点0，即分类结果。其中，相同颜色的圆圈表示网络中的共享参数。
节点之间共享参数的条件为：在Kd-tree中是同一层，且分割的方向都相同。可以看到节点8、9、12、13、14、15在同一层且分割的方向都相同：平行于y轴。

kd-tree和kd-net

kd-tree向量化公式
SO-Net#

    论文名 SO-Net: Self-Organizing Network for Point Cloud Analysis
    作者 Jiaxin Li ,Ben M.Chen Gim Hee Lee

SO-Net是一种用于无序点云深度学习的置换不变网络结构。它有如下两个特点：

    SO-Net通过构建自组织映射（SOM）来模拟点云的空间分布。
    基于SOM，SO-Net对单个点和SOM节点进行分层特征提取，最终用单个特征向量来表示输入点云。

    在识别点云重建，分类，对象部分分割和形状检索等任务中，So-Net网络表现出的性能与最先进的方法相似或更好。
    另外，由于所提出的架构的并行性和简单性，所以训练速度比现有的点云识别网络快得多。这篇论文发表在2018年的CVPR上。

理解这篇文章的重点在于了解自组织网络，我们先介绍什么是自组织网络，再进一步介绍自组织网络如何应用到点云数据上。
自组织网络#

自组织（竞争型）神经网络的结构一般由输入层和竞争层构成，两层之间的各个神经元实现双向连接，而且网络之间没有隐含层，有时候竞争层各个神经元之间还存在横向连接，其结构图如下所示。
学习算法上，它模拟生物神经元之间的兴奋、协调与抑制、竞争等作用的信息处理来指导神经元竞争对输入模型响应的机会，最后仅有一个神经元称为竞争的胜利者，这一神经元则表示对输入模型的分类。
SOM一般可以用于分类和聚类等任务。

avatar
SOM是一种自组织神经网络，它定义了独特的激活神经元选择策略、权重调整方法等。
SOM的最重要的特点是可以做保序映射。
1989年Kohonen给出一个SOM网的著名应用实例：把不同的动物按照其属性映射到二维输出平面上，使属性相同的动物在SOM网输出平面上的位置也相近。每种动物的输入为一个29维的向量，前16个分量采用独热编码，代表当前输入的是哪一个动物，后13个分量是该动物的属性值。
最终的输出结果如下图所示，可以看出，属性相同的动物挨在一起。即SOM将输入空间压缩并保留其拓扑空间映射在二维平面上。
因此SOM可以用于数据压缩和特征提取等任务。

我们可以用一个例子形象化的理解SOM拟合数据的过程。
如下图所示，蓝色部分是训练数据的分布，白色的小点是从该分布中抽取得到的当前训练数据。首先SOM随机的分布在数据空间中，我们选择最接近当前训练数据的SOM作为获胜节点，用黄色突出显示。
选出获胜节点后，我们更新获胜节点及其周围节点的参数，如图中的第二个状态所示，获胜节点及其周围节点被拉向训练数据。经过都次迭代后，SOM网格趋向于接近训练数据的分布。
avatar
SO-Net#

将SOM应用到点云数据上，效果如下图所示。可以看到，刚开始SOM数据点是随机分布在空间中，经过一段时间的训练可以可以拟合三维飞机形状的数据分布。
avatar
可知，SOM可以拟合点云的数据分布。
基于此，作者设计了SO-Net，具体结构如下图所示。
输入N3的点云数据，构建mm的SOM矩阵提取数据特征后，经过归一化，特征提取，和池化等操作后，得到m*384的特征矩阵，在经过全连接层和池化层，得到输入数据的特征向量，进一步做分类和分割。
（这边的具体过程没太看懂，感觉论文讲的有点混乱，符号似乎也有点问题，比如在做归一化的时候，是不是km*3？如果有看懂的小伙伴请留言谢谢！）
avatar
PU-Net#

    论文名 PU-Net: Point Cloud Upsampling Network
    作者 Lequan Yu,Xianzhi Li,Chi-Wing Fu等

    PU-Net在点云上进行上采样，即输入一个点云，输出一个更密的点云，且它落在输入点云隐含的几何体（比如表面）上。
    PU-Net的核心思想，是学习到每个点多个粒度（从局部到全局）下的特征，再在特征空间中扩大点集，最后将扩大的点集映射回三维。
    提取特征的方法基于PointNet++。其网络结构如下图所示：
如图所示，PU-Net主要分为四个过程：

Patch Extraction：这一过程其实是提取点云的若干个部分。
在模型表面上随机选择M个中心点，然后指定一个测地线距离d，将测地线距离范围内的点和中心点一起作为一个Patch。
采用不同的测地线距离d可以形成不同尺寸的patch。
Point Feature Embedding：这一过程包括两个阶段，特征提取和特征融合。
PU-Net采用PointNet++进行特征提取，即先对数据进行下采样，然后学习特征。
针对多个层次的特征，PU-Net采用三元插值算法进行特惠装呢个融合，图中绿色的部分即为通过红色的数据点插值得到的数据。
Feature Expansion：特征扩展的目的是将NC的特征矩阵扩展为rNC，其中r是上采样率。
我们可以先将NC扩展到rNC，在通过两个11的卷积核学习特征，再合并为一个rNC2的特征矩阵。
Coordinate Reconstruction：坐标重建的过程是将扩大的特征空间再映射回三维空间的过程。
通过多个全连接层，将rNC2的矩阵转化为rN3。

在这个过程中，值得一提的是，PU-Net为了使新生成的点均匀分布在数据表面，设计了两种损失函数：

    重建损失：为了使数据分布在数据模型表面。采用Earth Move Distance衡量生成的点云和ground truth之间的距离。其中ϕ

是一个从生成点云到ground truth的双射函数。
公式为：
Lrec=dEMD(Sp,Sgt)=minϕ:Sp→Sgt∑xi∈Sp|xi−ϕ(xi)|2

    排斥损失：如果只有重建损失，那么从一个点派生出来的r个点可能会聚集在一起，为了使这些点分开，需要增加排斥损失，其中距离越大，公式中的权重越大。
    公式为：$$L_{rep}=\sum^{\hat{N}}{i=0} \sum{i'\in K(i)} \eta (| x_{i'} -x_{i}|)w(| x_{i'}-x_{i} |)$$

总损失的计算公式为:

L(θ)=Lrec+αLrep+β∥θ∥2

其中β∥θ∥2

是正则化项。

PU-Net的效果图如下所示：
avatar
可以看出，它可以补全数据点中残缺的部分，上采样的效果非常好。

\subsubsection{分割方法}
\label{sec:05}
点云是一种能够完整表达场景信息的重要数据格式。
近年来,对于点云的探索引起了越来越多研究人员的关注,并且迅速在计算机视觉、自动驾驶和机器人等许多领域得到了广泛应用。
但是,由于点云独特的数据形式,使用深度神经网络处理点云时面临着独特挑战,因此基于点云的深度学习方法仍处于起步阶段。
最近,利用点云处理分割任务出现了许多优秀的方法。
为了激发未来对点云研究的深入发展,本文对点云深度学习方法的最新进展进行回顾,涵盖了三个主要任务,包括点云语义分割、点云实例分割以及常用的三维图像数据集,对其中处理点云的深度学习经典方法展开对比分析,提供多种方法在不同数据集上的比较结果,并且提出了一些观点和未来研究方向。
\bibliographystyle{plain}
\bibliography{ref} %这里的这个ref就是对文件ref.bib的引用
\end{document}
